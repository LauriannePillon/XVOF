"""
A module allowing exploitation of the Hdf5 output database
"""

import sys
import h5py
import numpy as np
from bisect import bisect
from xfv.src.output_manager.truefieldsbuilder import build_cell_true_field, build_node_true_field


class OutputDatabaseExploit(object):
    """
    A class for exploiting the output stored in Hdf5 database
    TODO : reconstruction des champs complets quand seulement une partie des cells sont enregistrees.
    """
    field_type_converter = {"Pressure": ("ClassicalPressure", "AdditionalPressure"),
                            "Stress": ("ClassicalStress", "AdditionalStress"),
                            "PlasticStrainRate": ("ClassicalPlasticStrainRate", "AdditionalPlasticStrainRate"),
                            "Density": ("ClassicalDensity", "AdditionalDensity"),
                            "InternalEnergy": ("ClassicalInternalEnergy", "AdditionalInternalEnergy"),
                            "SoundVelocity": ("ClassicalSoundVelocity", "AdditionalSoundVelocity"),
                            "ArtificialViscosity": ("ClassicalArtificialViscosity", "AdditionalArtificialViscosity"),
                            "DeviatoricStress": ("ClassicalDeviatoricStress", "AdditionalDeviatoricStress"),
                            "EquivalentPlasticStrainRate": ("ClassicalEquivalentPlasticStrainRate",
                                                            "AdditionalEquivalentPlasticStrainRate"),
                            "NodeVelocity": ("ClassicalNodeVelocity", "AdditionalNodeVelocity"),
                            "NodeCoordinates": ("NodeCoordinates", "None"),
                            "CohesiveForce": ("AdditionalCohesiveForce", "None"),
                            "DiscontinuityOpening": ("AdditionalDiscontinuityOpening", "None"),
                            "NodeStatus": ("NodeStatus", "None"),
                            "CellStatus": ("CellStatus", "None")}

    def __init__(self, path_to_db):
        self.__db = h5py.File(path_to_db, 'r')
        self.__saved_times = sorted([float(x) for x in list(self.__db.keys())])
        self.__nb_saved_times = len(self.saved_times)
        self.__saved_fields = list(self.__db.values())[0].keys()
        self.__saved_fields_type = [k for k, v in list(OutputDatabaseExploit.field_type_converter.items())
                                    if v[0] in self.__saved_fields]

    @property
    def nb_saved_times(self):
        """
        Return the number of time step that have been saved

        :return: the number of time step that have been saved
        """
        return self.__nb_saved_times

    @property
    def saved_times(self):
        """
        Return the list of saved times

        :return: the list of saved times
        """
        return self.__saved_times

    @property
    def saved_fields(self):
        """
        Return the different fields stored in the database

        :return: the different fields stored in the database
        """
        return self.__saved_fields

    @property
    def saved_fields_type(self):
        """
        Return the different fields type stored in the database

        :return: the different fields type stored in the database
        """
        return self.__saved_fields_type

    def get_cells_true_size_at_time(self, time):
        """
        Return the cells true sizes at time time

        :param time: time at which the cells sizes are computed
        :return: the cells true sizes
        """
        size = np.copy(self.extract_field_at_time("CellSize", time))
        cell_status = np.copy(self.extract_field_at_time("CellStatus", time))
        left_size, right_size = None, None
        try:
            left_size = self.extract_field_at_time("AdditionalLeftSize", time)[:].flatten()[1]
            right_size = self.extract_field_at_time("AdditionalRightSize", time)[:].flatten()[1]
        except KeyError:
            pass
        if left_size is not None and right_size is not None:
            offset = 0
            for stable_index in np.where(cell_status)[0]:
                moving_index = stable_index + offset
                size = np.insert(size, moving_index, [left_size, right_size])
                offset += 2
                size = np.delete(size, stable_index + offset)
        return size

    def get_cells_coordinate(self, time):
        """
        OK pour plusieurs discontinuites
        Return the cells center coordinate at time time
        :param time: time at which the cells coordinates are computed
        :return: the cells center coordinates
        """
        # Prise en compte de la longueur de la discontinuite :
        res = self.get_nodes_coordinates(time)
        node_position = np.copy(res).flatten()
        cell_size = np.copy(self.get_cells_true_size_at_time(time)).flatten()
        cell_status = self.extract_field_at_time("CellStatus", time)

        nbr_cells = len(cell_size)
        nbr_nodes = len(node_position)
        offset = 0

        if nbr_cells == nbr_nodes - 1:
            # ie on a pas enrichi (pas de size right inseree dans le vecteur des tailles)
            cell_position = node_position[:-1] + cell_size / 2.
        else:
            # Boucler sur les cell enrichies est le seul moyen de savoir si le noeud enrichi est a gauche ou a
            # droite de la discontinuite
            for stable_index in np.sort(np.where(cell_status)[0]):
                # en 1D, les indices des noeuds associes a chaque cell sont index et index + 1
                node_droite_index = stable_index + 1 + offset
                # on dedouble le noeud de droite car il permet de calculer la coordonnee de la partie droite
                # de la cell rompue ainsi que la coordonnee de la cell classique situee a droite de l'element rompu
                node_position = np.insert(
                                 node_position, node_droite_index, node_position[node_droite_index])
                # On anticipe la correction faite sur la coordonnee de la partie droite de la maille
                # (voir commentaire /!\ plus loin)
                node_position[node_droite_index] -= cell_size[node_droite_index]
                offset += 1

            # on calcule les coordonnees des cells pour les parties gauches
            cell_position = node_position[:-1] + cell_size / 2.
            # /!\ cette operation implique que les coordonnees de toutes les parties droites des elements rompus
            # sont mal calculees : pour chaque coordonnes des mailles rompues droites,
            # on calcule coord_cell_droite = coord_du_noeud_de_droite + taille_droite / 2 alors que la coord droite
            # s'obtient par l'operation coord_cell_droite = coord_du_noeud_de_droite - taille_droite / 2
            # => on effectue la correction coord_cell_droite = coord_cell_droite - taille_droite
            # pour retrouver la bonne coordonnee de la cell droite
        return cell_position.reshape((len(cell_size), 1))

    def get_nodes_coordinates(self, time):
        """
        Extract nodes coordinates from database
        """
        coord_item = self.extract_field_at_time("NodeCoordinates", time)
        return coord_item

    def extract_field_at_time(self, field_name, time):
        """
        Return the value of the specified field at time time in a numpy array

        :param field_name: name of the field to be extracted
        :param time: time at which the field has to be extracted
        :return: the values of the field at time time
        """
        ex_time = time
        if ex_time not in self.saved_times:
            ex_time_index = bisect(self.saved_times, time)
            if ex_time_index == self.nb_saved_times:
                ex_time_index = self.nb_saved_times - 1
            try:
                ex_time = self.saved_times[ex_time_index]
            except IndexError:
                print("Specified time is out of range. "
                      "Please specify a time in [{:15.9g}, {:15.9g}]"
                      .format(self.saved_times[0], self.saved_times[-1]), file=sys.stderr)
                raise
        try:
            if ex_time != 0.:
                field = self.__db[str(ex_time)][field_name]
            else:
                field = self.__db['0'][field_name]
        except KeyError:
            if field_name not in self.saved_fields:
                # to deal with the case where AdditionalField is not present in database
                # this is the case when the no enrichment is activated. This should not raise
                # an error as the field name verification has been done earlier
                raise
            else:
                print("Unable to retrieve the group {:s}".format(str(ex_time)), file=sys.stderr)
                raise
        return field

    def extract_true_field_at_time(self, field_type, time):
        """
        Return the value of the true field at time time in a numpy array

        :param field_type: type of the true field ("Pressure", "Density" ...)
        :param time: time at which the field has to be extracted
        :return: the values of the true field at time time
        """
        try:
            classical_fname, additional_fname = OutputDatabaseExploit.field_type_converter[field_type]
        except KeyError:
            print("The field type {:s} is not present in the database. "
                  "Available field types are {:s}!"
                  .format(field_type, ",".join(self.saved_fields_type)), file=sys.stderr)
            raise

        classical_f = self.extract_field_at_time(classical_fname, time)

        added_f = None
        coord_item = None
        try:
            added_f = self.extract_field_at_time(additional_fname, time)
        except KeyError:
            pass
        # Test du support :
        if "onedimension" not in classical_f.attrs["support"].lower():
            raise TypeError("I am not sure that it is a 1D analysis. "
                            "This may result in errors in the future")

        if added_f is None:  # Pas d'enrichissement : on recupere le champ classique
            true_field = classical_f[:]

            if len(true_field.flatten()) == true_field.shape[0]:
                # si le champ est un champ scalaire, on rentre dans la boucle et on reshape le np.array pour avoir
                # deux dimensions (dont une egale a 1). Cela permet d'avoirla compatibilite avec le type des coordonnees
                # des items pour np.concatenate
                true_field = true_field.reshape((len(true_field), 1))

            if "node" in classical_f.attrs["support"].lower():
                coord_item = self.get_nodes_coordinates(time)
            elif "cell" in classical_f.attrs["support"].lower():
                coord_item = self.get_cells_coordinate(time)

        else:  # Si le champ enrichi existe dans la base de donnee
            if "node" in classical_f.attrs["support"].lower():
                status_f = self.extract_field_at_time("NodeStatus", time)  # on recupere le booleen node.enriched
                coord_item = self.get_nodes_coordinates(time)
                # on reconstruit le champ vrai
                true_field = build_node_true_field(classical_f, added_f, status_f,
                                                   enrichment_type=added_f.attrs["enrichment"])
            elif "cell" in classical_f.attrs["support"].lower():
                coord_item = self.get_cells_coordinate(time)
                # on reconstruit le champ vrai
                # classical_field[:] pour donner le tabelau de valeur en argument plutot que le dataset
                true_field = build_cell_true_field(classical_f[:], added_f, enrichment_type=added_f.attrs["enrichment"])
            else:
                raise ValueError("Unknown support value!")

        # reconstruction d'un array coord / true field (pour les fields scalaires, vectoriels et tenseurs)
        # = version tenseur compatible de la methode np.concatenate((coord_item, true_field), axis=1)
        res = np.zeros([len(coord_item), true_field.shape[1] + 1])
        res[:, 0] = coord_item[:, 0]
        res[:, 1] = true_field[:, 0]
        # Et on essaye d'ajouter le reste des champs tensoriels
        try:
            res[:, 2] = true_field[:, 1]
            res[:, 3] = true_field[:, 2]
        except IndexError:
            # c'est que c'est un champ scalaire
            pass
        return res

    def extract_fields_for_cohesive_zone_model(self, indice_maille_rompue, time):
        """
        Read database to extract the discontinuity opening, cohesive force and a bool to filter results
        :param indice_maille_rompue : maille d'interet pour la zone cohesive
        :param time : time which to extract data at
        """
        exist = False
        opening = 0
        force = 0
        current_disc_collection = np.where(self.extract_field_at_time("CellStatus", time))[0]
        if indice_maille_rompue in current_disc_collection:
            exist = True
            op = self.extract_field_at_time("AdditionalDiscontinuityOpening", time)[:]  # tableau 2D indice, opening
            forc = self.extract_field_at_time("AdditionalCohesiveForce", time)[:]  # tableau 2D indice, force

            # retrouver la valeur qui va avec la maille indice_maille_rompue
            local_indice = np.where(op[:, 0] == indice_maille_rompue)[0][0]
            opening = op[local_indice, 1]
            force = forc[local_indice, 1]
        return exist, opening, force